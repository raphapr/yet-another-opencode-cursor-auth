// @generated by protoc-gen-es v1.10.0 with parameter "target=ts"
// @generated from file aiserver/v1/context.proto (package aiserver.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

/**
 * @generated from message aiserver.v1.PotentiallyCachedContextItem
 */
class PotentiallyCachedContextItem extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from oneof aiserver.v1.PotentiallyCachedContextItem.item
     */
    this.item = {
      case: undefined
    };
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new PotentiallyCachedContextItem().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new PotentiallyCachedContextItem().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new PotentiallyCachedContextItem().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(PotentiallyCachedContextItem, a, b);
  }
}
PotentiallyCachedContextItem.runtime = proto3 /* proto3 */.C;
PotentiallyCachedContextItem.typeName = "aiserver.v1.PotentiallyCachedContextItem";
PotentiallyCachedContextItem.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "context_item",
  kind: "message",
  T: ContextItem,
  oneof: "item"
}, {
  no: 2,
  name: "context_item_hash",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  oneof: "item"
}]);
/**
 * @generated from message aiserver.v1.ContextStatusUpdate
 */
class ContextStatusUpdate extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * ALL context items that were in the request MUST BE included in the response
     *
     * @generated from field: repeated aiserver.v1.ContextItemStatus context_item_statuses = 1;
     */
    this.contextItemStatuses = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextStatusUpdate().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextStatusUpdate().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextStatusUpdate().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextStatusUpdate, a, b);
  }
}
ContextStatusUpdate.runtime = proto3 /* proto3 */.C;
ContextStatusUpdate.typeName = "aiserver.v1.ContextStatusUpdate";
ContextStatusUpdate.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "context_item_statuses",
  kind: "message",
  T: ContextItemStatus,
  repeated: true
}]);
/**
 * @generated from message aiserver.v1.MissingContextItems
 */
class MissingContextItems extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * if there are any missing context items on the server (which can happen! could be evicted from the cache, could be routed to a new server because the pod crashed, etc) then the client should immediately retry the request with all the missing context items
     *
     * @generated from field: repeated string missing_context_item_hashes = 2;
     */
    this.missingContextItemHashes = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new MissingContextItems().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new MissingContextItems().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new MissingContextItems().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(MissingContextItems, a, b);
  }
}
MissingContextItems.runtime = proto3 /* proto3 */.C;
MissingContextItems.typeName = "aiserver.v1.MissingContextItems";
MissingContextItems.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 2,
  name: "missing_context_item_hashes",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  repeated: true
}]);
/**
 * @generated from message aiserver.v1.ContextItemStatus
 */
class ContextItemStatus extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string context_item_hash = 1;
     */
    this.contextItemHash = "";
    /**
     * @generated from field: bool shown_to_the_model = 2;
     */
    this.shownToTheModel = false;
    /**
     * higher score means more likely to be included by the model
     *
     * @generated from field: float score = 3;
     */
    this.score = 0;
    /**
     * percentage of available space tells you how much of the available context window this context item takes
     *
     * @generated from field: float percentage_of_available_space = 4;
     */
    this.percentageOfAvailableSpace = 0;
    /**
     * @generated from field: aiserver.v1.ContextItemStatus.PostGenerationEvaluation post_generation_evaluation = 5;
     */
    this.postGenerationEvaluation = ContextItemStatus_PostGenerationEvaluation.UNSPECIFIED;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItemStatus().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItemStatus().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItemStatus().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItemStatus, a, b);
  }
}
ContextItemStatus.runtime = proto3 /* proto3 */.C;
ContextItemStatus.typeName = "aiserver.v1.ContextItemStatus";
ContextItemStatus.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "context_item_hash",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "shown_to_the_model",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */
}, {
  no: 3,
  name: "score",
  kind: "scalar",
  T: 2 /* ScalarType.FLOAT */
}, {
  no: 4,
  name: "percentage_of_available_space",
  kind: "scalar",
  T: 2 /* ScalarType.FLOAT */
}, {
  no: 5,
  name: "post_generation_evaluation",
  kind: "enum",
  T: proto3 /* proto3 */.C.getEnumType(ContextItemStatus_PostGenerationEvaluation)
}]);
/**
 * @generated from enum aiserver.v1.ContextItemStatus.PostGenerationEvaluation
 */
var ContextItemStatus_PostGenerationEvaluation;
(function (ContextItemStatus_PostGenerationEvaluation) {
  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_UNSPECIFIED = 0;
   */
  ContextItemStatus_PostGenerationEvaluation[ContextItemStatus_PostGenerationEvaluation["UNSPECIFIED"] = 0] = "UNSPECIFIED";
  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_USEFUL = 1;
   */
  ContextItemStatus_PostGenerationEvaluation[ContextItemStatus_PostGenerationEvaluation["USEFUL"] = 1] = "USEFUL";
  /**
   * @generated from enum value: POST_GENERATION_EVALUATION_USELESS = 2;
   */
  ContextItemStatus_PostGenerationEvaluation[ContextItemStatus_PostGenerationEvaluation["USELESS"] = 2] = "USELESS";
})(ContextItemStatus_PostGenerationEvaluation || (ContextItemStatus_PostGenerationEvaluation = {}));
// Retrieve enum metadata with: proto3.getEnumType(ContextItemStatus_PostGenerationEvaluation)
proto3 /* proto3 */.C.util.setEnumType(ContextItemStatus_PostGenerationEvaluation, "aiserver.v1.ContextItemStatus.PostGenerationEvaluation", [{
  no: 0,
  name: "POST_GENERATION_EVALUATION_UNSPECIFIED"
}, {
  no: 1,
  name: "POST_GENERATION_EVALUATION_USEFUL"
}, {
  no: 2,
  name: "POST_GENERATION_EVALUATION_USELESS"
}]);
/**
 * the context item is the unit of context
 * it cannot be split up
 * each one should be independently renderable and not depend on anything else — not actually obvious to me!
 * if T is the rendered length of the context item, the space used by the serialized context item must be O(T)
 *
 * @generated from message aiserver.v1.ContextItem
 */
class ContextItem extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * feel free to be liberal about adding types here. we can handle a lot of them, and it's better to let different things be different than to introduce unnecessary coupling
     *
     * @generated from oneof aiserver.v1.ContextItem.item
     */
    this.item = {
      case: undefined
    };
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem, a, b);
  }
}
ContextItem.runtime = proto3 /* proto3 */.C;
ContextItem.typeName = "aiserver.v1.ContextItem";
ContextItem.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "intent",
  kind: "message",
  T: ContextIntent
}, {
  no: 2,
  name: "file_chunk",
  kind: "message",
  T: ContextItem_FileChunk,
  oneof: "item"
}, {
  no: 3,
  name: "outline_chunk",
  kind: "message",
  T: ContextItem_OutlineChunk,
  oneof: "item"
}, {
  no: 4,
  name: "cmd_k_selection",
  kind: "message",
  T: ContextItem_CmdKSelection,
  oneof: "item"
}, {
  no: 5,
  name: "cmd_k_immediate_context",
  kind: "message",
  T: ContextItem_CmdKImmediateContext,
  oneof: "item"
}, {
  no: 6,
  name: "cmd_k_query",
  kind: "message",
  T: ContextItem_CmdKQuery,
  oneof: "item"
}, {
  no: 7,
  name: "cmd_k_query_history",
  kind: "message",
  T: ContextItem_CmdKQueryHistory,
  oneof: "item"
}, {
  no: 8,
  name: "custom_instructions",
  kind: "message",
  T: ContextItem_CustomInstructions,
  oneof: "item"
}, {
  no: 9,
  name: "go_to_definition_result",
  kind: "message",
  T: ContextItem_GoToDefinitionResult,
  oneof: "item"
}, {
  no: 10,
  name: "documentation_chunk",
  kind: "message",
  T: ContextItem_DocumentationChunk,
  oneof: "item"
}, {
  no: 11,
  name: "lints",
  kind: "message",
  T: ContextItem_Lints,
  oneof: "item"
}, {
  no: 12,
  name: "chat_history",
  kind: "message",
  T: ContextItem_ChatHistory,
  oneof: "item"
}, {
  no: 13,
  name: "notebook_cell_output",
  kind: "message",
  T: ContextItem_NotebookCellOutput,
  oneof: "item"
}, {
  no: 14,
  name: "terminal_history",
  kind: "message",
  T: ContextItem_TerminalHistory,
  oneof: "item"
}, {
  no: 15,
  name: "terminal_cmd_k_query",
  kind: "message",
  T: ContextItem_TerminalCmdKQuery,
  oneof: "item"
}, {
  no: 16,
  name: "terminal_cmd_k_query_history",
  kind: "message",
  T: ContextItem_TerminalCmdKQueryHistory,
  oneof: "item"
}, {
  no: 17,
  name: "sparse_file_chunk",
  kind: "message",
  T: ContextItem_SparseFileChunk,
  oneof: "item"
}, {
  no: 18,
  name: "lsp_subgraph_chunk",
  kind: "message",
  T: ContextItem_LspSubgraphChunk,
  oneof: "item"
}, {
  no: 19,
  name: "commit_note_chunk",
  kind: "message",
  T: ContextItem_CommitNoteChunk,
  oneof: "item"
}, {
  no: 20,
  name: "file_diff_history",
  kind: "message",
  T: ContextItem_FileDiffHistory,
  oneof: "item"
}, {
  no: 21,
  name: "cmd_k_query_history_in_diff_session",
  kind: "message",
  T: ContextItem_CmdKQueryHistoryInDiffSession,
  oneof: "item"
}, {
  no: 22,
  name: "project_rule",
  kind: "message",
  T: utils_pb /* CursorRule */.DX,
  oneof: "item"
}]);
/**
 * file chunk is just a plain simple chunk taken directly from a file
 * processed chunks are either OutlineChunks or something else!
 *
 * @generated from message aiserver.v1.ContextItem.FileChunk
 */
class ContextItem_FileChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * why not do a repeated lines thing here?
     *
     * @generated from field: string chunk_contents = 2;
     */
    this.chunkContents = "";
    /**
     * we only include start line number and nothing else, to make sure our data storage is not redundant
     * end line number is implied by the number of lines
     * and we always replace entire lines, so column numbers are not necessary
     *
     * @generated from field: int32 start_line_number = 3;
     */
    this.startLineNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_FileChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_FileChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_FileChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_FileChunk, a, b);
  }
}
ContextItem_FileChunk.runtime = proto3 /* proto3 */.C;
ContextItem_FileChunk.typeName = "aiserver.v1.ContextItem.FileChunk";
ContextItem_FileChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "chunk_contents",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "start_line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.SparseFileChunk
 */
class ContextItem_SparseFileChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * it is VERY IMPORTANT that these lines NOT BE SPOOFED
     * they MUST correspond to REAL LINES in the file, always.
     * instead of spoofing, please think of a way not to spoof
     * for example: for generates, we do not spoof to say there is no empty line (which we insert when the user does cmd+k), but rather we include the empty line here, we include the empty line as a deletion in the response, and then we just have a way on the client where we do not show the deleted lines in the diff
     * the reason to be adamant about this is that many other context items will reference line numbers (lints, chunks, etc), and we want to make sure that gpt-4 gets to see a consistent view of the file and the world. otherwise, it will be confused!
     *
     * @generated from field: repeated aiserver.v1.ContextItem.SparseFileChunk.Line lines = 2;
     */
    this.lines = [];
    /**
     * @generated from field: int32 total_number_of_lines_in_file = 3;
     */
    this.totalNumberOfLinesInFile = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_SparseFileChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_SparseFileChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_SparseFileChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_SparseFileChunk, a, b);
  }
}
ContextItem_SparseFileChunk.runtime = proto3 /* proto3 */.C;
ContextItem_SparseFileChunk.typeName = "aiserver.v1.ContextItem.SparseFileChunk";
ContextItem_SparseFileChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "lines",
  kind: "message",
  T: ContextItem_SparseFileChunk_Line,
  repeated: true
}, {
  no: 3,
  name: "total_number_of_lines_in_file",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 4,
  name: "cell_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextItem.SparseFileChunk.Line
 */
class ContextItem_SparseFileChunk_Line extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string line = 1;
     */
    this.line = "";
    /**
     * @generated from field: int32 line_number = 2;
     */
    this.lineNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_SparseFileChunk_Line().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_SparseFileChunk_Line().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_SparseFileChunk_Line().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_SparseFileChunk_Line, a, b);
  }
}
ContextItem_SparseFileChunk_Line.runtime = proto3 /* proto3 */.C;
ContextItem_SparseFileChunk_Line.typeName = "aiserver.v1.ContextItem.SparseFileChunk.Line";
ContextItem_SparseFileChunk_Line.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "line",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.OutlineChunk
 */
class ContextItem_OutlineChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * for now we don't really provide any structured data here. we could if we wanted to
     *
     * @generated from field: string contents = 2;
     */
    this.contents = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_OutlineChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_OutlineChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_OutlineChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_OutlineChunk, a, b);
  }
}
ContextItem_OutlineChunk.runtime = proto3 /* proto3 */.C;
ContextItem_OutlineChunk.typeName = "aiserver.v1.ContextItem.OutlineChunk";
ContextItem_OutlineChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "contents",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "full_range",
  kind: "message",
  T: utils_pb /* LineRange */.MT
}]);
/**
 * generates also have a cmd-k selection!
 * for generates, we always add an empty line to generate within
 * so the selection will be whitespace only! but it always is included!
 *
 * @generated from message aiserver.v1.ContextItem.CmdKSelection
 */
class ContextItem_CmdKSelection extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * we don't need a workspace path because this is always in the given file
     * we just send up the selection plain and simple
     * if this is a generate, the lines here will be empty! (or maybe one empty line?)
     *
     * @generated from field: repeated string lines = 1;
     */
    this.lines = [];
    /**
     * the end line number is implied by the number of lines
     *
     * @generated from field: int32 start_line_number = 2;
     */
    this.startLineNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKSelection().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKSelection().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKSelection().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKSelection, a, b);
  }
}
ContextItem_CmdKSelection.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKSelection.typeName = "aiserver.v1.ContextItem.CmdKSelection";
ContextItem_CmdKSelection.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "lines",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  repeated: true
}, {
  no: 2,
  name: "start_line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.FileDiffHistory
 */
class ContextItem_FileDiffHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * this is 0 for the most-recent file diff history, 1 for the next, etc
     *
     * @generated from field: int32 how_many_diffs_ago = 2;
     */
    this.howManyDiffsAgo = 0;
    /**
     * if it's very recent, then getScoredContextItems will score it highly, i.e. above all automatically-attached reranked ctx items. otherwise it gets reranked with the rest of them.
     * idea is that very recent commits have super local edits, and completeness matters a lot
     * and not-very-recent commits are more just places to copy code from
     * NOTE: the reranked diff history is only used in evals rn!
     * Doesn't seem to do much better than just naive, truncated diff history
     *
     * @generated from field: bool is_very_recent = 3;
     */
    this.isVeryRecent = false;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_FileDiffHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_FileDiffHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_FileDiffHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_FileDiffHistory, a, b);
  }
}
ContextItem_FileDiffHistory.runtime = proto3 /* proto3 */.C;
ContextItem_FileDiffHistory.typeName = "aiserver.v1.ContextItem.FileDiffHistory";
ContextItem_FileDiffHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "cpp_file_diff_history",
  kind: "message",
  T: CppFileDiffHistory
}, {
  no: 2,
  name: "how_many_diffs_ago",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 3,
  name: "is_very_recent",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CmdKImmediateContext
 */
class ContextItem_CmdKImmediateContext extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * it is VERY IMPORTANT that these lines NOT BE SPOOFED
     * they MUST correspond to REAL LINES in the file, always.
     * instead of spoofing, please think of a way not to spoof
     * for example: for generates, we do not spoof to say there is no empty line (which we insert when the user does cmd+k), but rather we include the empty line here, we include the empty line as a deletion in the response, and then we just have a way on the client where we do not show the deleted lines in the diff
     * the reason to be adamant about this is that many other context items will reference line numbers (lints, chunks, etc), and we want to make sure that gpt-4 gets to see a consistent view of the file and the world. otherwise, it will be confused!
     *
     * @generated from field: repeated aiserver.v1.ContextItem.CmdKImmediateContext.Line lines = 2;
     */
    this.lines = [];
    /**
     * @generated from field: int32 total_number_of_lines_in_file = 3;
     */
    this.totalNumberOfLinesInFile = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKImmediateContext().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKImmediateContext().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKImmediateContext().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKImmediateContext, a, b);
  }
}
ContextItem_CmdKImmediateContext.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKImmediateContext.typeName = "aiserver.v1.ContextItem.CmdKImmediateContext";
ContextItem_CmdKImmediateContext.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "lines",
  kind: "message",
  T: ContextItem_CmdKImmediateContext_Line,
  repeated: true
}, {
  no: 3,
  name: "total_number_of_lines_in_file",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 4,
  name: "cell_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CmdKImmediateContext.Line
 */
class ContextItem_CmdKImmediateContext_Line extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string line = 1;
     */
    this.line = "";
    /**
     * @generated from field: int32 line_number = 2;
     */
    this.lineNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKImmediateContext_Line().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKImmediateContext_Line().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKImmediateContext_Line().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKImmediateContext_Line, a, b);
  }
}
ContextItem_CmdKImmediateContext_Line.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKImmediateContext_Line.typeName = "aiserver.v1.ContextItem.CmdKImmediateContext.Line";
ContextItem_CmdKImmediateContext_Line.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "line",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CmdKQuery
 */
class ContextItem_CmdKQuery extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string query = 1;
     */
    this.query = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKQuery().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKQuery().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKQuery().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKQuery, a, b);
  }
}
ContextItem_CmdKQuery.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKQuery.typeName = "aiserver.v1.ContextItem.CmdKQuery";
ContextItem_CmdKQuery.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "query",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.TerminalCmdKQuery
 */
class ContextItem_TerminalCmdKQuery extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string query = 1;
     */
    this.query = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_TerminalCmdKQuery().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_TerminalCmdKQuery().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_TerminalCmdKQuery().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_TerminalCmdKQuery, a, b);
  }
}
ContextItem_TerminalCmdKQuery.runtime = proto3 /* proto3 */.C;
ContextItem_TerminalCmdKQuery.typeName = "aiserver.v1.ContextItem.TerminalCmdKQuery";
ContextItem_TerminalCmdKQuery.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "query",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.TerminalCmdKQueryHistory
 */
class ContextItem_TerminalCmdKQueryHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: repeated string context_item_hashes = 5;
     */
    this.contextItemHashes = [];
    /**
     * @generated from field: string suggested_command = 6;
     */
    this.suggestedCommand = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_TerminalCmdKQueryHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_TerminalCmdKQueryHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_TerminalCmdKQueryHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_TerminalCmdKQueryHistory, a, b);
  }
}
ContextItem_TerminalCmdKQueryHistory.runtime = proto3 /* proto3 */.C;
ContextItem_TerminalCmdKQueryHistory.typeName = "aiserver.v1.ContextItem.TerminalCmdKQueryHistory";
ContextItem_TerminalCmdKQueryHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "query",
  kind: "message",
  T: ContextItem_TerminalCmdKQuery
}, {
  no: 2,
  name: "query_history",
  kind: "message",
  T: ContextItem_TerminalCmdKQueryHistory
}, {
  no: 5,
  name: "context_item_hashes",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  repeated: true
}, {
  no: 6,
  name: "suggested_command",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CmdKQueryHistory
 */
class ContextItem_CmdKQueryHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * finally, we also include a hash of all context items that were SHOWN to the model in the previous request
     * this is useful for caching! it also makes the model's job easier, by putting past context at the top and only new context at the end
     * things may be confusing for the model if you include any hashes that were not shown to the model, since then the assistant response may look like it just ignored things..
     *
     * @generated from field: repeated string context_item_hashes = 5;
     */
    this.contextItemHashes = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKQueryHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKQueryHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKQueryHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKQueryHistory, a, b);
  }
}
ContextItem_CmdKQueryHistory.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKQueryHistory.typeName = "aiserver.v1.ContextItem.CmdKQueryHistory";
ContextItem_CmdKQueryHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "query",
  kind: "message",
  T: ContextItem_CmdKQuery
}, {
  no: 2,
  name: "immediate_context",
  kind: "message",
  T: ContextItem_CmdKImmediateContext
}, {
  no: 3,
  name: "selection",
  kind: "message",
  T: ContextItem_CmdKSelection
}, {
  no: 4,
  name: "query_history",
  kind: "message",
  T: ContextItem_CmdKQueryHistory
}, {
  no: 5,
  name: "context_item_hashes",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  repeated: true
}, {
  no: 6,
  name: "timestamp",
  kind: "scalar",
  T: 3 /* ScalarType.INT64 */,
  opt: true
}, {
  no: 7,
  name: "timestamp_double",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */,
  opt: true
}]);
/**
 * this lets ppl do multiple cmdks in the same session
 * kinda worried it'll make the model confused though - what if the ppl get angry and tell it to do X in file Y, but then it thinks it should do X in file Z?
 * that's surprising to user
 *
 * @generated from message aiserver.v1.ContextItem.CmdKQueryHistoryInDiffSession
 */
class ContextItem_CmdKQueryHistoryInDiffSession extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: repeated aiserver.v1.ContextItem.CmdKQueryHistoryInDiffSession.PastCmdKQueryInDiffSession past_cmdk_queries = 1;
     */
    this.pastCmdkQueries = [];
    /**
     * @generated from field: double curr_timestamp_double = 3;
     */
    this.currTimestampDouble = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKQueryHistoryInDiffSession, a, b);
  }
}
ContextItem_CmdKQueryHistoryInDiffSession.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKQueryHistoryInDiffSession.typeName = "aiserver.v1.ContextItem.CmdKQueryHistoryInDiffSession";
ContextItem_CmdKQueryHistoryInDiffSession.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "past_cmdk_queries",
  kind: "message",
  T: ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession,
  repeated: true
}, {
  no: 3,
  name: "curr_timestamp_double",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CmdKQueryHistoryInDiffSession.PastCmdKQueryInDiffSession
 */
class ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * relative workspace path of the file the query was run in
     *
     * @generated from field: string relative_workspace_path = 2;
     */
    this.relativeWorkspacePath = "";
    /**
     * @generated from field: double timestamp_double = 6;
     */
    this.timestampDouble = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession, a, b);
  }
}
ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession.runtime = proto3 /* proto3 */.C;
ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession.typeName = "aiserver.v1.ContextItem.CmdKQueryHistoryInDiffSession.PastCmdKQueryInDiffSession";
ContextItem_CmdKQueryHistoryInDiffSession_PastCmdKQueryInDiffSession.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "query",
  kind: "message",
  T: ContextItem_CmdKQuery
}, {
  no: 2,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 5,
  name: "cmdk_was_accepted",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */,
  opt: true
}, {
  no: 6,
  name: "timestamp_double",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */
}, {
  no: 7,
  name: "timestamp_for_diff_interleaving",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */,
  opt: true
}, {
  no: 8,
  name: "request_id",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextItem.ChatHistory
 */
class ContextItem_ChatHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string user_message = 1;
     */
    this.userMessage = "";
    /**
     * @generated from field: string assistant_response = 2;
     */
    this.assistantResponse = "";
    /**
     * this is true if the chat history is the currently active chat history for cmd+k
     * this only needs to be set on the top-level item
     *
     * @generated from field: bool active_for_cmd_k = 4;
     */
    this.activeForCmdK = false;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_ChatHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_ChatHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_ChatHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_ChatHistory, a, b);
  }
}
ContextItem_ChatHistory.runtime = proto3 /* proto3 */.C;
ContextItem_ChatHistory.typeName = "aiserver.v1.ContextItem.ChatHistory";
ContextItem_ChatHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "user_message",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "assistant_response",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "chat_history",
  kind: "message",
  T: ContextItem_ChatHistory
}, {
  no: 4,
  name: "active_for_cmd_k",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */
}, {
  no: 5,
  name: "timestamp",
  kind: "scalar",
  T: 3 /* ScalarType.INT64 */,
  opt: true
}, {
  no: 6,
  name: "timestamp_double",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */,
  opt: true
}]);
/**
 * TODO: should this be split into multiple context items? how should we use context items that clearly need to be seen in context with each other, but may be really big and need to be chosen how big they should be?
 *
 * @generated from message aiserver.v1.ContextItem.TerminalHistory
 */
class ContextItem_TerminalHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string history = 1;
     */
    this.history = "";
    /**
     * @generated from field: string cwd_full = 5;
     */
    this.cwdFull = "";
    /**
     * @generated from field: string cwd_relative_workspace_path = 6;
     */
    this.cwdRelativeWorkspacePath = "";
    /**
     * this is true if the terminal history is currently active for the cmd-k (i.e. we are in a cmd-k box in the terminal)
     *
     * @generated from field: bool active_for_cmd_k = 4;
     */
    this.activeForCmdK = false;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_TerminalHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_TerminalHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_TerminalHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_TerminalHistory, a, b);
  }
}
ContextItem_TerminalHistory.runtime = proto3 /* proto3 */.C;
ContextItem_TerminalHistory.typeName = "aiserver.v1.ContextItem.TerminalHistory";
ContextItem_TerminalHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "history",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 5,
  name: "cwd_full",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 6,
  name: "cwd_relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 4,
  name: "active_for_cmd_k",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */
}, {
  no: 7,
  name: "timestamp",
  kind: "scalar",
  T: 3 /* ScalarType.INT64 */,
  opt: true
}, {
  no: 8,
  name: "timestamp_double",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CustomInstructions
 */
class ContextItem_CustomInstructions extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string instructions = 1;
     */
    this.instructions = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CustomInstructions().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CustomInstructions().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CustomInstructions().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CustomInstructions, a, b);
  }
}
ContextItem_CustomInstructions.runtime = proto3 /* proto3 */.C;
ContextItem_CustomInstructions.typeName = "aiserver.v1.ContextItem.CustomInstructions";
ContextItem_CustomInstructions.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "instructions",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.GoToDefinitionResult
 */
class ContextItem_GoToDefinitionResult extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * we specify the position we went to definition on
     *
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * @generated from field: string line = 2;
     */
    this.line = "";
    /**
     * 1-indexed! ofcourse!
     *
     * @generated from field: int32 line_number = 3;
     */
    this.lineNumber = 0;
    /**
     * 1-indexed! of course!
     *
     * @generated from field: int32 column_number = 4;
     */
    this.columnNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_GoToDefinitionResult().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_GoToDefinitionResult().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_GoToDefinitionResult().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_GoToDefinitionResult, a, b);
  }
}
ContextItem_GoToDefinitionResult.runtime = proto3 /* proto3 */.C;
ContextItem_GoToDefinitionResult.typeName = "aiserver.v1.ContextItem.GoToDefinitionResult";
ContextItem_GoToDefinitionResult.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "line",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 4,
  name: "column_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 5,
  name: "definition_chunk",
  kind: "message",
  T: ContextItem_FileChunk
}]);
/**
 * @generated from message aiserver.v1.ContextItem.DocumentationChunk
 */
class ContextItem_DocumentationChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string doc_name = 1;
     */
    this.docName = "";
    /**
     * @generated from field: string page_url = 2;
     */
    this.pageUrl = "";
    /**
     * @generated from field: string documentation_chunk = 3;
     */
    this.documentationChunk = "";
    /**
     * docs chunks are currently reranked first separately, getting the score below. the global reranker may or may not take this into account
     * it is possible we want to remove this score and just do the reranking in the global reranker itself. but it feels wasteful to just throw out this score, which we will alway get for free from doing the embedding retrieval!
     *
     * @generated from field: float score = 4;
     */
    this.score = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_DocumentationChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_DocumentationChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_DocumentationChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_DocumentationChunk, a, b);
  }
}
ContextItem_DocumentationChunk.runtime = proto3 /* proto3 */.C;
ContextItem_DocumentationChunk.typeName = "aiserver.v1.ContextItem.DocumentationChunk";
ContextItem_DocumentationChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "doc_name",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "page_url",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "documentation_chunk",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 4,
  name: "score",
  kind: "scalar",
  T: 2 /* ScalarType.FLOAT */
}]);
/**
 * we currently keep many lints in the same context item
 * the reason is that many of them build on each other, and it is probably easier to see all of them together
 * they are also all generally small enough that they don't need to be reranked separately
 * if we ever want to rerank separately, just introduce a new message here, called SingleLint or something like that
 *
 * @generated from message aiserver.v1.ContextItem.Lints
 */
class ContextItem_Lints extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * @generated from field: repeated aiserver.v1.Lint lints = 2;
     */
    this.lints = [];
    /**
     * the context lines will potentially contain a few lines above/below the affected ranges
     *
     * @generated from field: repeated aiserver.v1.ContextItem.Lints.Line context_lines = 3;
     */
    this.contextLines = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_Lints().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_Lints().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_Lints().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_Lints, a, b);
  }
}
ContextItem_Lints.runtime = proto3 /* proto3 */.C;
ContextItem_Lints.typeName = "aiserver.v1.ContextItem.Lints";
ContextItem_Lints.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "lints",
  kind: "message",
  T: utils_pb /* Lint */.U1,
  repeated: true
}, {
  no: 3,
  name: "context_lines",
  kind: "message",
  T: ContextItem_Lints_Line,
  repeated: true
}]);
/**
 * @generated from message aiserver.v1.ContextItem.Lints.Line
 */
class ContextItem_Lints_Line extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string line = 1;
     */
    this.line = "";
    /**
     * @generated from field: int32 line_number = 2;
     */
    this.lineNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_Lints_Line().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_Lints_Line().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_Lints_Line().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_Lints_Line, a, b);
  }
}
ContextItem_Lints_Line.runtime = proto3 /* proto3 */.C;
ContextItem_Lints_Line.typeName = "aiserver.v1.ContextItem.Lints.Line";
ContextItem_Lints_Line.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "line",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "line_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.NotebookCellOutput
 */
class ContextItem_NotebookCellOutput extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * the cell output here may be truncated!
     *
     * @generated from field: string cell_output = 2;
     */
    this.cellOutput = "";
    /**
     * 1-indexed!
     *
     * @generated from field: int32 cell_number = 3;
     */
    this.cellNumber = 0;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_NotebookCellOutput().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_NotebookCellOutput().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_NotebookCellOutput().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_NotebookCellOutput, a, b);
  }
}
ContextItem_NotebookCellOutput.runtime = proto3 /* proto3 */.C;
ContextItem_NotebookCellOutput.typeName = "aiserver.v1.ContextItem.NotebookCellOutput";
ContextItem_NotebookCellOutput.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "cell_output",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 3,
  name: "cell_number",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}]);
/**
 * @generated from message aiserver.v1.ContextItem.LspSubgraphChunk
 */
class ContextItem_LspSubgraphChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_LspSubgraphChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_LspSubgraphChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_LspSubgraphChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_LspSubgraphChunk, a, b);
  }
}
ContextItem_LspSubgraphChunk.runtime = proto3 /* proto3 */.C;
ContextItem_LspSubgraphChunk.typeName = "aiserver.v1.ContextItem.LspSubgraphChunk";
ContextItem_LspSubgraphChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "lsp_subgraph_full_context",
  kind: "message",
  T: LspSubgraphFullContext
}]);
/**
 * @generated from message aiserver.v1.ContextItem.CommitNoteChunk
 */
class ContextItem_CommitNoteChunk extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string note = 1;
     */
    this.note = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextItem_CommitNoteChunk().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextItem_CommitNoteChunk().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextItem_CommitNoteChunk().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextItem_CommitNoteChunk, a, b);
  }
}
ContextItem_CommitNoteChunk.runtime = proto3 /* proto3 */.C;
ContextItem_CommitNoteChunk.typeName = "aiserver.v1.ContextItem.CommitNoteChunk";
ContextItem_CommitNoteChunk.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "note",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * hmm why should the context intent be a proto type?
 * does the server ever need the context intent?
 * oh yeah it needs to know the context intent for each context item i think
 *
 * @generated from message aiserver.v1.ContextIntent
 */
class ContextIntent extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * the type decides how highly the context is prioritized
     * for example, user added context is always added above the automatic context
     *
     * @generated from field: aiserver.v1.ContextIntent.Type type = 1;
     */
    this.type = ContextIntent_Type.UNSPECIFIED;
    /**
     * the uuid is used to identify the context intent
     * so that th handler can be updated
     *
     * @generated from field: string uuid = 15;
     */
    this.uuid = "";
    /**
     * @generated from oneof aiserver.v1.ContextIntent.intent
     */
    this.intent = {
      case: undefined
    };
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent, a, b);
  }
}
ContextIntent.runtime = proto3 /* proto3 */.C;
ContextIntent.typeName = "aiserver.v1.ContextIntent";
ContextIntent.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "type",
  kind: "enum",
  T: proto3 /* proto3 */.C.getEnumType(ContextIntent_Type)
}, {
  no: 15,
  name: "uuid",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "file",
  kind: "message",
  T: ContextIntent_File,
  oneof: "intent"
}, {
  no: 3,
  name: "code_selection",
  kind: "message",
  T: ContextIntent_CodeSelection,
  oneof: "intent"
}, {
  no: 5,
  name: "lints",
  kind: "message",
  T: ContextIntent_Lints,
  oneof: "intent"
}, {
  no: 6,
  name: "recent_locations",
  kind: "message",
  T: ContextIntent_RecentLocations,
  oneof: "intent"
}, {
  no: 8,
  name: "cmd_k_current_file",
  kind: "message",
  T: ContextIntent_CmdKCurrentFile,
  oneof: "intent"
}, {
  no: 9,
  name: "cmd_k_query_etc",
  kind: "message",
  T: ContextIntent_CmdKQueryEtc,
  oneof: "intent"
}, {
  no: 14,
  name: "terminal_cmd_k_defaults",
  kind: "message",
  T: ContextIntent_TerminalCmdKDefaults,
  oneof: "intent"
}, {
  no: 10,
  name: "cmd_k_definitions",
  kind: "message",
  T: ContextIntent_CmdKDefinitions,
  oneof: "intent"
}, {
  no: 11,
  name: "documentation",
  kind: "message",
  T: ContextIntent_Documentation,
  oneof: "intent"
}, {
  no: 12,
  name: "custom_instructions",
  kind: "message",
  T: ContextIntent_CustomInstructions,
  oneof: "intent"
}, {
  no: 13,
  name: "chat_history",
  kind: "message",
  T: ContextIntent_ChatHistory,
  oneof: "intent"
}, {
  no: 16,
  name: "terminal_history",
  kind: "message",
  T: ContextIntent_TerminalHistory,
  oneof: "intent"
}, {
  no: 17,
  name: "visible_tabs",
  kind: "message",
  T: ContextIntent_VisibleTabs,
  oneof: "intent"
}, {
  no: 18,
  name: "lsp_subgraph",
  kind: "message",
  T: ContextIntent_LspSubgraph,
  oneof: "intent"
}, {
  no: 19,
  name: "commit_notes",
  kind: "message",
  T: ContextIntent_CommitNotes,
  oneof: "intent"
}, {
  no: 20,
  name: "diff_history",
  kind: "message",
  T: ContextIntent_DiffHistory,
  oneof: "intent"
}, {
  no: 21,
  name: "past_cmdk_messages_in_diff_sessions",
  kind: "message",
  T: ContextIntent_PastCmdkConversationsInDiffSessions,
  oneof: "intent"
}]);
/**
 * @generated from enum aiserver.v1.ContextIntent.Type
 */
var ContextIntent_Type;
(function (ContextIntent_Type) {
  /**
   * @generated from enum value: TYPE_UNSPECIFIED = 0;
   */
  ContextIntent_Type[ContextIntent_Type["UNSPECIFIED"] = 0] = "UNSPECIFIED";
  /**
   * @generated from enum value: TYPE_USER_ADDED = 1;
   */
  ContextIntent_Type[ContextIntent_Type["USER_ADDED"] = 1] = "USER_ADDED";
  /**
   * it is possible that we want to add more types here...
   *
   * @generated from enum value: TYPE_AUTOMATIC = 2;
   */
  ContextIntent_Type[ContextIntent_Type["AUTOMATIC"] = 2] = "AUTOMATIC";
})(ContextIntent_Type || (ContextIntent_Type = {}));
// Retrieve enum metadata with: proto3.getEnumType(ContextIntent_Type)
proto3 /* proto3 */.C.util.setEnumType(ContextIntent_Type, "aiserver.v1.ContextIntent.Type", [{
  no: 0,
  name: "TYPE_UNSPECIFIED"
}, {
  no: 1,
  name: "TYPE_USER_ADDED"
}, {
  no: 2,
  name: "TYPE_AUTOMATIC"
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.Documentation
 */
class ContextIntent_Documentation extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string documentation_identifier = 1;
     */
    this.documentationIdentifier = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_Documentation().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_Documentation().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_Documentation().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_Documentation, a, b);
  }
}
ContextIntent_Documentation.runtime = proto3 /* proto3 */.C;
ContextIntent_Documentation.typeName = "aiserver.v1.ContextIntent.Documentation";
ContextIntent_Documentation.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "documentation_identifier",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.File
 */
class ContextIntent_File extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * @generated from field: aiserver.v1.ContextIntent.File.Mode mode = 2;
     */
    this.mode = ContextIntent_File_Mode.UNSPECIFIED;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_File().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_File().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_File().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_File, a, b);
  }
}
ContextIntent_File.runtime = proto3 /* proto3 */.C;
ContextIntent_File.typeName = "aiserver.v1.ContextIntent.File";
ContextIntent_File.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "mode",
  kind: "enum",
  T: proto3 /* proto3 */.C.getEnumType(ContextIntent_File_Mode)
}]);
/**
 * @generated from enum aiserver.v1.ContextIntent.File.Mode
 */
var ContextIntent_File_Mode;
(function (ContextIntent_File_Mode) {
  /**
   * in UNSPECIFIED mode, we predict the correct mode heuristically
   *
   * @generated from enum value: MODE_UNSPECIFIED = 0;
   */
  ContextIntent_File_Mode[ContextIntent_File_Mode["UNSPECIFIED"] = 0] = "UNSPECIFIED";
  /**
   * @generated from enum value: MODE_FULL = 1;
   */
  ContextIntent_File_Mode[ContextIntent_File_Mode["FULL"] = 1] = "FULL";
  /**
   * @generated from enum value: MODE_OUTLINE = 2;
   */
  ContextIntent_File_Mode[ContextIntent_File_Mode["OUTLINE"] = 2] = "OUTLINE";
  /**
   * @generated from enum value: MODE_CHUNKS = 3;
   */
  ContextIntent_File_Mode[ContextIntent_File_Mode["CHUNKS"] = 3] = "CHUNKS";
})(ContextIntent_File_Mode || (ContextIntent_File_Mode = {}));
// Retrieve enum metadata with: proto3.getEnumType(ContextIntent_File_Mode)
proto3 /* proto3 */.C.util.setEnumType(ContextIntent_File_Mode, "aiserver.v1.ContextIntent.File.Mode", [{
  no: 0,
  name: "MODE_UNSPECIFIED"
}, {
  no: 1,
  name: "MODE_FULL"
}, {
  no: 2,
  name: "MODE_OUTLINE"
}, {
  no: 3,
  name: "MODE_CHUNKS"
}]);
/**
 * ARVIDTODO: how to deal with the code selections? they are special because often they are "part of the prompt" and not explicitly referred to with an @ symbol. the user just kind of assumes that there is knowledge of it
 * maybe we always insert @ symbols for each code selection? that would solve this problem, i think
 *
 * @generated from message aiserver.v1.ContextIntent.CodeSelection
 */
class ContextIntent_CodeSelection extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    /**
     * the text is the source of truth
     * it may contain \r\n or \n depending on the source
     * this becomes kind of redundant with the context item...
     *
     * @generated from field: string text = 3;
     */
    this.text = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CodeSelection().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CodeSelection().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CodeSelection().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CodeSelection, a, b);
  }
}
ContextIntent_CodeSelection.runtime = proto3 /* proto3 */.C;
ContextIntent_CodeSelection.typeName = "aiserver.v1.ContextIntent.CodeSelection";
ContextIntent_CodeSelection.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "potentially_out_of_date_range",
  kind: "message",
  T: utils_pb /* SimpleRange */._u
}, {
  no: 3,
  name: "text",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.Symbol
 */
class ContextIntent_Symbol extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 2;
     */
    this.relativeWorkspacePath = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_Symbol().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_Symbol().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_Symbol().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_Symbol, a, b);
  }
}
ContextIntent_Symbol.runtime = proto3 /* proto3 */.C;
ContextIntent_Symbol.typeName = "aiserver.v1.ContextIntent.Symbol";
ContextIntent_Symbol.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "symbol",
  kind: "message",
  T: utils_pb /* DocumentSymbol */.Az
}, {
  no: 2,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.CommitNotes
 */
class ContextIntent_CommitNotes extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CommitNotes().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CommitNotes().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CommitNotes().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CommitNotes, a, b);
  }
}
ContextIntent_CommitNotes.runtime = proto3 /* proto3 */.C;
ContextIntent_CommitNotes.typeName = "aiserver.v1.ContextIntent.CommitNotes";
ContextIntent_CommitNotes.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * @generated from message aiserver.v1.ContextIntent.Lints
 */
class ContextIntent_Lints extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from oneof aiserver.v1.ContextIntent.Lints.scope
     */
    this.scope = {
      case: undefined
    };
    /**
     * if this is empty, we allow all severities
     * otherwise, we restrict to only the given severities
     *
     * @generated from field: repeated aiserver.v1.LintSeverity filter_to_severities = 3;
     */
    this.filterToSeverities = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_Lints().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_Lints().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_Lints().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_Lints, a, b);
  }
}
ContextIntent_Lints.runtime = proto3 /* proto3 */.C;
ContextIntent_Lints.typeName = "aiserver.v1.ContextIntent.Lints";
ContextIntent_Lints.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "cmdk_scope",
  kind: "message",
  T: ContextIntent_Lints_CmdKScope,
  oneof: "scope"
}, {
  no: 2,
  name: "file_scope",
  kind: "message",
  T: ContextIntent_Lints_FileScope,
  oneof: "scope"
}, {
  no: 3,
  name: "filter_to_severities",
  kind: "enum",
  T: proto3 /* proto3 */.C.getEnumType(utils_pb /* LintSeverity */.x$),
  repeated: true
}]);
/**
 * we use the current file and the given range.
 * in the future, we may want to add an option here for a "plus-minus" on the range, or the ability to use all linter errors in the entire file
 *
 * @generated from message aiserver.v1.ContextIntent.Lints.CmdKScope
 */
class ContextIntent_Lints_CmdKScope extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_Lints_CmdKScope().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_Lints_CmdKScope().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_Lints_CmdKScope().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_Lints_CmdKScope, a, b);
  }
}
ContextIntent_Lints_CmdKScope.runtime = proto3 /* proto3 */.C;
ContextIntent_Lints_CmdKScope.typeName = "aiserver.v1.ContextIntent.Lints.CmdKScope";
ContextIntent_Lints_CmdKScope.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * @generated from message aiserver.v1.ContextIntent.Lints.FileScope
 */
class ContextIntent_Lints_FileScope extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: string relative_workspace_path = 1;
     */
    this.relativeWorkspacePath = "";
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_Lints_FileScope().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_Lints_FileScope().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_Lints_FileScope().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_Lints_FileScope, a, b);
  }
}
ContextIntent_Lints_FileScope.runtime = proto3 /* proto3 */.C;
ContextIntent_Lints_FileScope.typeName = "aiserver.v1.ContextIntent.Lints.FileScope";
ContextIntent_Lints_FileScope.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "relative_workspace_path",
  kind: "scalar",
  T: 9 /* ScalarType.STRING */
}, {
  no: 2,
  name: "filter_range",
  kind: "message",
  T: utils_pb /* LineRange */.MT,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.RecentLocations
 */
class ContextIntent_RecentLocations extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_RecentLocations().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_RecentLocations().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_RecentLocations().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_RecentLocations, a, b);
  }
}
ContextIntent_RecentLocations.runtime = proto3 /* proto3 */.C;
ContextIntent_RecentLocations.typeName = "aiserver.v1.ContextIntent.RecentLocations";
ContextIntent_RecentLocations.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 2,
  name: "timestamp",
  kind: "scalar",
  T: 1 /* ScalarType.DOUBLE */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.PastCmdkConversationsInDiffSessions
 */
class ContextIntent_PastCmdkConversationsInDiffSessions extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_PastCmdkConversationsInDiffSessions().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_PastCmdkConversationsInDiffSessions().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_PastCmdkConversationsInDiffSessions().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_PastCmdkConversationsInDiffSessions, a, b);
  }
}
ContextIntent_PastCmdkConversationsInDiffSessions.runtime = proto3 /* proto3 */.C;
ContextIntent_PastCmdkConversationsInDiffSessions.typeName = "aiserver.v1.ContextIntent.PastCmdkConversationsInDiffSessions";
ContextIntent_PastCmdkConversationsInDiffSessions.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * from Andrew: not sure what this is for, but no options here either :)
 *
 * @generated from message aiserver.v1.ContextIntent.VisibleTabs
 */
class ContextIntent_VisibleTabs extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_VisibleTabs().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_VisibleTabs().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_VisibleTabs().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_VisibleTabs, a, b);
  }
}
ContextIntent_VisibleTabs.runtime = proto3 /* proto3 */.C;
ContextIntent_VisibleTabs.typeName = "aiserver.v1.ContextIntent.VisibleTabs";
ContextIntent_VisibleTabs.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * we currently don't have any options here
 * it is possible that we want to add in the advanced context building options here!
 *
 * @generated from message aiserver.v1.ContextIntent.CodebaseChunks
 */
class ContextIntent_CodebaseChunks extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CodebaseChunks().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CodebaseChunks().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CodebaseChunks().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CodebaseChunks, a, b);
  }
}
ContextIntent_CodebaseChunks.runtime = proto3 /* proto3 */.C;
ContextIntent_CodebaseChunks.typeName = "aiserver.v1.ContextIntent.CodebaseChunks";
ContextIntent_CodebaseChunks.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * not really any options here either
 * this one is always required to be included? maybe there's some option for only restricted to the really needed part
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKCurrentFile
 */
class ContextIntent_CmdKCurrentFile extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CmdKCurrentFile().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CmdKCurrentFile().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CmdKCurrentFile().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CmdKCurrentFile, a, b);
  }
}
ContextIntent_CmdKCurrentFile.runtime = proto3 /* proto3 */.C;
ContextIntent_CmdKCurrentFile.typeName = "aiserver.v1.ContextIntent.CmdKCurrentFile";
ContextIntent_CmdKCurrentFile.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * always included! includes both the query and the history
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKQueryEtc
 */
class ContextIntent_CmdKQueryEtc extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CmdKQueryEtc().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CmdKQueryEtc().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CmdKQueryEtc().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CmdKQueryEtc, a, b);
  }
}
ContextIntent_CmdKQueryEtc.runtime = proto3 /* proto3 */.C;
ContextIntent_CmdKQueryEtc.typeName = "aiserver.v1.ContextIntent.CmdKQueryEtc";
ContextIntent_CmdKQueryEtc.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * currently this only works for the global custom instructions (also known as explicit context)
 * it is possible that this should work with e.g. README.ai.md files too!
 *
 * @generated from message aiserver.v1.ContextIntent.CustomInstructions
 */
class ContextIntent_CustomInstructions extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CustomInstructions().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CustomInstructions().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CustomInstructions().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CustomInstructions, a, b);
  }
}
ContextIntent_CustomInstructions.runtime = proto3 /* proto3 */.C;
ContextIntent_CustomInstructions.typeName = "aiserver.v1.ContextIntent.CustomInstructions";
ContextIntent_CustomInstructions.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * if we bring it in manually, perhaps we want to give people the option of specifying how many types to include and whether to recurse or not?
 * also the range!
 *
 * @generated from message aiserver.v1.ContextIntent.CmdKDefinitions
 */
class ContextIntent_CmdKDefinitions extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_CmdKDefinitions().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_CmdKDefinitions().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_CmdKDefinitions().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_CmdKDefinitions, a, b);
  }
}
ContextIntent_CmdKDefinitions.runtime = proto3 /* proto3 */.C;
ContextIntent_CmdKDefinitions.typeName = "aiserver.v1.ContextIntent.CmdKDefinitions";
ContextIntent_CmdKDefinitions.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * currently chat history can only take the main chat
 * in the future it may be interesting to be able to @ a specific chat history? e.g. using the chat ID
 * yep! and then the intent can either be "current" to always use the current chat (which tbh we probably never want) or a specific chat ID to use that
 *
 * @generated from message aiserver.v1.ContextIntent.ChatHistory
 */
class ContextIntent_ChatHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_ChatHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_ChatHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_ChatHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_ChatHistory, a, b);
  }
}
ContextIntent_ChatHistory.runtime = proto3 /* proto3 */.C;
ContextIntent_ChatHistory.typeName = "aiserver.v1.ContextIntent.ChatHistory";
ContextIntent_ChatHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * Navid's diffs taken from telem data. Will need to change to make it work at inference-time.
 *
 * @generated from message aiserver.v1.ContextIntent.DiffHistory
 */
class ContextIntent_DiffHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_DiffHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_DiffHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_DiffHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_DiffHistory, a, b);
  }
}
ContextIntent_DiffHistory.runtime = proto3 /* proto3 */.C;
ContextIntent_DiffHistory.typeName = "aiserver.v1.ContextIntent.DiffHistory";
ContextIntent_DiffHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * @generated from message aiserver.v1.ContextIntent.TerminalCmdKDefaults
 */
class ContextIntent_TerminalCmdKDefaults extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_TerminalCmdKDefaults().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_TerminalCmdKDefaults().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_TerminalCmdKDefaults().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_TerminalCmdKDefaults, a, b);
  }
}
ContextIntent_TerminalCmdKDefaults.runtime = proto3 /* proto3 */.C;
ContextIntent_TerminalCmdKDefaults.typeName = "aiserver.v1.ContextIntent.TerminalCmdKDefaults";
ContextIntent_TerminalCmdKDefaults.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);
/**
 * @generated from message aiserver.v1.ContextIntent.TerminalHistory
 */
class ContextIntent_TerminalHistory extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: int32 instance_id = 1;
     */
    this.instanceId = 0;
    /**
     * @generated from field: bool active_for_cmd_k = 2;
     */
    this.activeForCmdK = false;
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_TerminalHistory().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_TerminalHistory().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_TerminalHistory().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_TerminalHistory, a, b);
  }
}
ContextIntent_TerminalHistory.runtime = proto3 /* proto3 */.C;
ContextIntent_TerminalHistory.typeName = "aiserver.v1.ContextIntent.TerminalHistory";
ContextIntent_TerminalHistory.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "instance_id",
  kind: "scalar",
  T: 5 /* ScalarType.INT32 */
}, {
  no: 2,
  name: "active_for_cmd_k",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */
}, {
  no: 3,
  name: "use_active_instance_as_fallback",
  kind: "scalar",
  T: 8 /* ScalarType.BOOL */,
  opt: true
}]);
/**
 * @generated from message aiserver.v1.ContextIntent.LspSubgraph
 */
class ContextIntent_LspSubgraph extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new ContextIntent_LspSubgraph().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new ContextIntent_LspSubgraph().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new ContextIntent_LspSubgraph().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(ContextIntent_LspSubgraph, a, b);
  }
}
ContextIntent_LspSubgraph.runtime = proto3 /* proto3 */.C;
ContextIntent_LspSubgraph.typeName = "aiserver.v1.ContextIntent.LspSubgraph";
ContextIntent_LspSubgraph.fields = proto3 /* proto3 */.C.util.newFieldList(() => []);