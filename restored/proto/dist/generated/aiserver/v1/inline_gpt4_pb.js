// @generated by protoc-gen-es v1.10.0 with parameter "target=ts"
// @generated from file aiserver/v1/inline_gpt4.proto (package aiserver.v1, syntax proto3)
/* eslint-disable */
// @ts-nocheck

/**
 * @generated from message aiserver.v1.InlineGPT4PromptProtoV1
 */
class InlineGPT4PromptProtoV1 extends message /* Message */.Q {
  constructor(data) {
    super();
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new InlineGPT4PromptProtoV1().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new InlineGPT4PromptProtoV1().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new InlineGPT4PromptProtoV1().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(InlineGPT4PromptProtoV1, a, b);
  }
}
InlineGPT4PromptProtoV1.runtime = proto3 /* proto3 */.C;
InlineGPT4PromptProtoV1.typeName = "aiserver.v1.InlineGPT4PromptProtoV1";
InlineGPT4PromptProtoV1.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "current_file",
  kind: "message",
  T: utils_pb /* CurrentFileInfo */.qW
}]);
/**
 * @generated from message aiserver.v1.StreamInlineLongCompletionRequest
 */
class StreamInlineLongCompletionRequest extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: repeated aiserver.v1.RepositoryInfo repositories = 6;
     */
    this.repositories = [];
    /**
     * @generated from field: repeated aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock context_blocks = 7;
     */
    this.contextBlocks = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new StreamInlineLongCompletionRequest().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new StreamInlineLongCompletionRequest().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new StreamInlineLongCompletionRequest().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(StreamInlineLongCompletionRequest, a, b);
  }
}
StreamInlineLongCompletionRequest.runtime = proto3 /* proto3 */.C;
StreamInlineLongCompletionRequest.typeName = "aiserver.v1.StreamInlineLongCompletionRequest";
StreamInlineLongCompletionRequest.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "current_file",
  kind: "message",
  T: utils_pb /* CurrentFileInfo */.qW
}, {
  no: 6,
  name: "repositories",
  kind: "message",
  T: repository_pb /* RepositoryInfo */.bn,
  repeated: true
}, {
  no: 7,
  name: "context_blocks",
  kind: "message",
  T: StreamInlineLongCompletionRequest_ContextBlock,
  repeated: true
}, {
  no: 13,
  name: "explicit_context",
  kind: "message",
  T: utils_pb /* ExplicitContext */.Y1
}, {
  no: 14,
  name: "model_details",
  kind: "message",
  T: utils_pb /* ModelDetails */.Gm
}, {
  no: 15,
  name: "linter_errors",
  kind: "message",
  T: utils_pb /* LinterErrors */.wZ
}]);
/**
 * @generated from message aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock
 */
class StreamInlineLongCompletionRequest_ContextBlock extends message /* Message */.Q {
  constructor(data) {
    super();
    /**
     * @generated from field: aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock.ContextType context_type = 1;
     */
    this.contextType = StreamInlineLongCompletionRequest_ContextBlock_ContextType.UNSPECIFIED;
    /**
     * @generated from field: repeated aiserver.v1.CodeBlock blocks = 2;
     */
    this.blocks = [];
    proto3 /* proto3 */.C.util.initPartial(data, this);
  }
  static fromBinary(bytes, options) {
    return new StreamInlineLongCompletionRequest_ContextBlock().fromBinary(bytes, options);
  }
  static fromJson(jsonValue, options) {
    return new StreamInlineLongCompletionRequest_ContextBlock().fromJson(jsonValue, options);
  }
  static fromJsonString(jsonString, options) {
    return new StreamInlineLongCompletionRequest_ContextBlock().fromJsonString(jsonString, options);
  }
  static equals(a, b) {
    return proto3 /* proto3 */.C.util.equals(StreamInlineLongCompletionRequest_ContextBlock, a, b);
  }
}
StreamInlineLongCompletionRequest_ContextBlock.runtime = proto3 /* proto3 */.C;
StreamInlineLongCompletionRequest_ContextBlock.typeName = "aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock";
StreamInlineLongCompletionRequest_ContextBlock.fields = proto3 /* proto3 */.C.util.newFieldList(() => [{
  no: 1,
  name: "context_type",
  kind: "enum",
  T: proto3 /* proto3 */.C.getEnumType(StreamInlineLongCompletionRequest_ContextBlock_ContextType)
}, {
  no: 2,
  name: "blocks",
  kind: "message",
  T: utils_pb /* CodeBlock */.NG,
  repeated: true
}]);
/**
 * @generated from enum aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock.ContextType
 */
var StreamInlineLongCompletionRequest_ContextBlock_ContextType;
(function (StreamInlineLongCompletionRequest_ContextBlock_ContextType) {
  /**
   * @generated from enum value: CONTEXT_TYPE_UNSPECIFIED = 0;
   */
  StreamInlineLongCompletionRequest_ContextBlock_ContextType[StreamInlineLongCompletionRequest_ContextBlock_ContextType["UNSPECIFIED"] = 0] = "UNSPECIFIED";
  /**
   * @generated from enum value: CONTEXT_TYPE_RECENT_LOCATIONS = 1;
   */
  StreamInlineLongCompletionRequest_ContextBlock_ContextType[StreamInlineLongCompletionRequest_ContextBlock_ContextType["RECENT_LOCATIONS"] = 1] = "RECENT_LOCATIONS";
})(StreamInlineLongCompletionRequest_ContextBlock_ContextType || (StreamInlineLongCompletionRequest_ContextBlock_ContextType = {}));
// Retrieve enum metadata with: proto3.getEnumType(StreamInlineLongCompletionRequest_ContextBlock_ContextType)
proto3 /* proto3 */.C.util.setEnumType(StreamInlineLongCompletionRequest_ContextBlock_ContextType, "aiserver.v1.StreamInlineLongCompletionRequest.ContextBlock.ContextType", [{
  no: 0,
  name: "CONTEXT_TYPE_UNSPECIFIED"
}, {
  no: 1,
  name: "CONTEXT_TYPE_RECENT_LOCATIONS"
}]);